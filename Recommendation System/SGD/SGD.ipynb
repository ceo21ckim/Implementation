{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np \r\n",
    "from tqdm import tqdm_notebook as tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- R : 평점 행렬\r\n",
    "- k : User Latent와 item Latent 차원의 수 \r\n",
    "- learning_rate : 학습률\r\n",
    "- reg_param : Weight의 Regularization 값\r\n",
    "- epochs : 전체 학습 횟수\r\n",
    "- verbose = 학습 과정을 출력할지 여부( True : 10번마다 cost 출력, False : cost 출력 x )"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class MatrixFactorization():\r\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose = False):\r\n",
    "        \"\"\"\r\n",
    "        :param R: rating matrix\r\n",
    "        :param k: latent parameter\r\n",
    "        :param learning_rate: alpha on weight update\r\n",
    "        :param reg_param: beta on weight update\r\n",
    "        :param epochs: training epochs\r\n",
    "        :param verbose: print status\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self._R = R \r\n",
    "        self._num_users, self._num_items = R.shape\r\n",
    "        self._k = k \r\n",
    "        self._learning_rate = learning_rate \r\n",
    "        self._reg_param = reg_param\r\n",
    "        self._epochs = epochs\r\n",
    "        self._verbose = verbose \r\n",
    "\r\n",
    "    def fit(self):\r\n",
    "        \"\"\"\r\n",
    "        training Matrix Factorization : Update matrix latent weight and bias \r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        # init latent features\r\n",
    "        self._P = np.random.normal(size = (self._num_users, self._k))\r\n",
    "        self._Q = np.random.normal(size = (self._num_items, self._k))\r\n",
    "\r\n",
    "        # init biases\r\n",
    "        self._b_P = np.zeros(self._num_users)\r\n",
    "        self._b_Q = np.zeros(self._num_items)\r\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\r\n",
    "        # 각 유저마다 평점을 평가할 때 후한지, 짜게 주는지에 따라 bias가 발생할 수 있기 때문에\r\n",
    "        # 해당 유저의 평균을 빼줌으로써 bias를 제거할 수 있다. \r\n",
    "\r\n",
    "        # train while epochs\r\n",
    "        self._training_process = []\r\n",
    "        for epoch in range(self._epochs):\r\n",
    "            xi, yi = self._R.nonzero()\r\n",
    "            for i, j in zip(xi, yi) :\r\n",
    "                self.gradient_descent(i, j, self._R[i,j])\r\n",
    "            cost = self.cost()\r\n",
    "            self._training_process.append((epoch, cost))\r\n",
    "\r\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0) :\r\n",
    "                print(\"Iteration : %d ; cost = %.4f\" %(epoch + 1, cost))\r\n",
    "\r\n",
    "\r\n",
    "    def gradient_descent(self, i, j, rating):\r\n",
    "        \r\n",
    "        # get error\r\n",
    "        prediction = self.get_prediction(i, j)\r\n",
    "        error = rating - prediction\r\n",
    "\r\n",
    "        # update biases\r\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\r\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\r\n",
    "\r\n",
    "        # update latent feature\r\n",
    "        dp, dq = self.gradient(error, i, j)\r\n",
    "        self._P[i, :] += self._learning_rate * dp\r\n",
    "        self._Q[j, :] += self._learning_rate * dq \r\n",
    "\r\n",
    "\r\n",
    "    def cost(self):\r\n",
    "        xi, yi = self._R.nonzero()\r\n",
    "\r\n",
    "        cost = 0\r\n",
    "\r\n",
    "        for x, y in zip(xi, yi):\r\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\r\n",
    "        return np.sqrt(cost / len(xi))\r\n",
    "\r\n",
    "\r\n",
    "    def gradient(self, error, i, j):\r\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\r\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\r\n",
    "        return dp, dq\r\n",
    "\r\n",
    "    \r\n",
    "    def get_prediction(self, i, j):\r\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\r\n",
    "\r\n",
    "    \r\n",
    "    def get_complete_matrix(self):\r\n",
    "        return self._b + self.b_P[:, np.newaxis] + self._b_Q[np.newaxis, :] + self._P.dot(self._Q.T)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__' :\r\n",
    "    R = np.array([\r\n",
    "        [1, 0, 0, 1, 3],\r\n",
    "        [2, 0, 3, 1, 1],\r\n",
    "        [1, 2, 0, 5, 0],\r\n",
    "        [1, 0, 0, 4, 4],\r\n",
    "        [2, 1, 5, 4, 0],\r\n",
    "        [5, 1, 5, 4, 0],\r\n",
    "        [0, 0, 0, 1, 0]\r\n",
    "    ])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%%time \r\n",
    "\r\n",
    "factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\r\n",
    "factorizer.fit()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration : 10 ; cost = 1.0807\n",
      "Iteration : 20 ; cost = 0.6732\n",
      "Iteration : 30 ; cost = 0.4633\n",
      "Iteration : 40 ; cost = 0.3551\n",
      "Iteration : 50 ; cost = 0.2964\n",
      "Iteration : 60 ; cost = 0.2596\n",
      "Iteration : 70 ; cost = 0.2320\n",
      "Iteration : 80 ; cost = 0.2086\n",
      "Iteration : 90 ; cost = 0.1874\n",
      "Iteration : 100 ; cost = 0.1679\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "96cf18f209edf6220e7043c3825950920f4c7ad96ff42ffae85e8b73f5a9541f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}