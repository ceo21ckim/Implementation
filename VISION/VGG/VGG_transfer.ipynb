{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np \n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 폴더가 존재하지 않는 경우 작성한다\n",
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet의 class_index를 다운로드한다\n",
    "# Keras에서 제공하는 항목\n",
    "# https://github.com/fchollet/deep-learning-models/blob/master/imagenet_utils.py\n",
    "\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3절에서 사용하는 개미와 벌의 화상 데이터를 다운로드하여 압축을 해제한다\n",
    "# PyTorch의 튜토리얼로 제공되는 항목\n",
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)\n",
    "\n",
    "    # ZIP 파일을 읽는다\n",
    "    zip = zipfile.ZipFile(save_path)\n",
    "    zip.extractall(data_dir)  # ZIP을 압축 해제\n",
    "    zip.close()  # ZIP 파일을 닫는다\n",
    "\n",
    "    # ZIP 파일을 삭제\n",
    "    os.remove(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※실시 완료 사항\n",
    "\n",
    "골든 리트리버 이미지를 수동 다운로드\n",
    "\n",
    "https://pixabay.com/ja/photos/goldenretriever-%E7%8A%AC-3724972/\n",
    "의 640×426 사이즈 화상\n",
    "(사진 권리 정보: CC0 Creative Commons, 상용 이용 무료, 저작자 표시 필요 없음)을, data 폴더 바로 아래에 배치함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomResizedCrop을 지정된 scale로 이미지를 확대 및 축소를 한다\n",
    "#### RandomRHorizontalFlip을 통해 좌우를 50% 확률로 반전시킨다.\n",
    "\n",
    "데이터의 수가 적을땐 위 과정을 통해 데이터를 증폭시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train' : transforms.Compose([\n",
    "                transforms.RandomResizedCrop(\n",
    "                resize, scale = (0.5, 1.0)), # 데이터 확장\n",
    "                transforms.RandomHorizontalFlip(), # 데이터 확장\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val' : transforms.Compose([\n",
    "                transforms.Resize(resize),\n",
    "                transforms.CenterCrop(resize), \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    def __call__(self, img, phase = 'train'):\n",
    "        return self.data_transform[phase](img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = './data/goldenretriever-3724972_960_720.jpg'\n",
    "img = Image.open(image_file_path)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224 \n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "transform = ImageTransform(size, mean, std)\n",
    "img_transformed = transform(img, phase = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c x h x w 를 h x w x c 로 변환하고, 0~1 로 값을 제한.\n",
    "img_transformed = img_transformed.transpose((1, 2, 0))\n",
    "img_transformed = np.clip(img_transformed, 0, 1)\n",
    "plt.imshow(img_transformed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개미, 벌 분류 : train 243장, val 153장\n",
    "def make_datapath_list(phase = 'train'):\n",
    "    rootpath = './data/hymenoptera_data/'\n",
    "    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n",
    "    path_list = []\n",
    "    \n",
    "    for path in glob.glob(target_path): # 파일 경로를 가지고 온다.\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list \n",
    "\n",
    "\n",
    "train_list = make_datapath_list(phase = 'train')\n",
    "val_list = make_datapath_list(phase = 'val')\n",
    "\n",
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HymenopteraDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            label = img_path[30:34]\n",
    "        elif self.phase == 'val':\n",
    "            label = img_path[28:32]\n",
    "            \n",
    "        if label == 'ants':\n",
    "            label = 0\n",
    "            \n",
    "        elif label == 'bees':\n",
    "            label = 1\n",
    "            \n",
    "        return img_transformed, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HymenopteraDataset( file_list = train_list, transform = ImageTransform(size, mean, std),\n",
    "                                  phase = 'train')\n",
    "\n",
    "val_dataset = HymenopteraDataset(file_list = val_list, transform = ImageTransform(size, mean, std),\n",
    "                                phase = 'val')\n",
    "\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size())\n",
    "print(val_dataset.__getitem__(index)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니 배치 크기 지정\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터 로더 작성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# 사전형 변수에 정리.\n",
    "dataloaders_dict = {'train' : train_dataloader, 'val' : val_dataloader}\n",
    "\n",
    "batch_iterator = iter(dataloaders_dict['train'])\n",
    "inputs, labels = next(batch_iterator) # 첫번째 요소 추출\n",
    "print(inputs.size())\n",
    "print(labels)\n",
    "print(labels[labels == 1].size(), labels[labels == 0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 VGG-16 모델 로드 \n",
    "use_pretrained = True\n",
    "net = models.vgg16(pretrained=use_pretrained).to(device)\n",
    "\n",
    "# 벌과 개미 두가지 클래스로 분류하기 때문에 마지막 fc.layer를 수정해준다.\n",
    "net.classifier[6] = nn.Linear(in_features = 4096, out_features=2).to(device)\n",
    "\n",
    "net.train()\n",
    "print('네트워크 설정 완료 : 학습된 가중치를 읽어들여 훈련 모드로 설정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained 된 모델의 파라미터를 고정할 때 설정.\n",
    "requires_grad = False\n",
    "\n",
    "# transfer-learning에서 학습시킬 파라미터를 저장\n",
    "params_to_update = []\n",
    "\n",
    "update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True\n",
    "        params_to_update.append(param)\n",
    "        print(name)\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "print('------------')\n",
    "print(params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params = params_to_update, lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1} / {num_epochs}')\n",
    "        print('-----------------')\n",
    "        \n",
    "        # 에폭별 학습 및 검증 루프\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            # 학습하지 않을 시 검증 성능을 학인하기 위해 epoch = 0의 훈련 생략\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "                \n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    y_pred = torch.argmax(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    epoch_corrects += (y_pred == labels).sum().item()\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects / len(dataloaders_dict[phase].dataset)\n",
    "            print(f'{phase} Loss : {epoch_loss :.4f}, Acc : {epoch_acc:.4f}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
